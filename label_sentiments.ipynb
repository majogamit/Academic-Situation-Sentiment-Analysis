{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "devoted-manner",
   "metadata": {},
   "source": [
    "## Label Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worth-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "# For Data processing/cleaning\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import STOPWORDS\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import os\n",
    "import warnings\n",
    "from numpy import loadtxt\n",
    "from nltk import tokenize\n",
    "\n",
    "# import WhitespaceTokenizer() method from nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "substantial-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"03_Data_with_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "disabled-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import text file into NumPy array\n",
    "neg_fil = loadtxt('negative_words_tl.txt', dtype='object')\n",
    "pos_fil = loadtxt('positive_words_tl.txt', dtype='object')\n",
    "badwords_fil = [\"amputa\",\"animal ka\",\"bilat\",\"binibrocha\",\"bobo\",\"bogo\",\"boto\",\"brocha\",\"burat\",\"bwesit\",\"bwisit\",\"demonyo ka\",\"engot\",\"etits\",\"gaga\",\"gagi\",\"gago\",\"habal\",\"hayop ka\",\"hayup\",\"hinampak\",\"hinayupak\",\"hindot\",\"hindutan\",\"hudas\",\"iniyot\",\"inutel\",\"inutil\",\"iyot\",\"kagaguhan\",\"kagang\",\"kantot\",\"kantotan\",\"kantut\",\"kantutan\",\"kaululan\",\"kayat\",\"kiki\",\"kikinginamo\",\"kingina\",\"kupal\",\"leche\",\"leching\",\"lechugas\",\"lintik\",\"nakakaburat\",\"nimal\",\"ogag\",\"olok\",\"pakingshet\",\"pakshet\",\"pakyu\",\"pesteng yawa\",\"poke\",\"poki\",\"pokpok\",\"poyet\",\"pu'keng\",\"pucha\",\"puchanggala\",\"puchangina\",\"puke\",\"puki\",\"pukinangina\",\"puking\",\"punyeta\",\"puta\",\"putang\",\"putang ina\",\"putangina\",\"putanginamo\",\"putaragis\",\"putragis\",\"puyet\",\"ratbu\",\"shunga\",\"sira ulo\",\"siraulo\",\"suso\",\"susu\",\"tae\",\"taena\",\"tamod\",\"tanga\",\"tangina\",\"taragis\",\"tarantado\",\"tete\",\"teti\",\"timang\",\"tinil\",\"tite\",\"titi\",\"tungaw\",\"ulol\",\"ulul\",\"ungas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "physical-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_fil = np.concatenate((neg_fil, badwords_fil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "solid-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_eng = loadtxt('negative_words_en.txt', dtype='object')\n",
    "pos_eng = loadtxt('positive_words_en.txt', dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fatty-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_data = np.concatenate((neg_fil, neg_eng))\n",
    "positive_data = np.concatenate((pos_fil, pos_eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "regulation-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5926,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "invisible-mitchell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2818,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "latin-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[['absolute_tidy_tweets', 'stopped_tweets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-glucose",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conscious-easter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_tidy_tweets</th>\n",
       "      <th>stopped_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#academicbreaknow</td>\n",
       "      <td>#academicbreaknow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello #AcademicTwitter You need to have a rest...</td>\n",
       "      <td>hello #academictwitter need rest activate best...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lunes nanaman bukas #academicbreaknow</td>\n",
       "      <td>lunes nanaman bukas #academicbreaknow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#AcademicBreakNow gusto q na tapusin Wednesday</td>\n",
       "      <td>#academicbreaknow q tapusin wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>super delay na ako sa tbw list ko #academicbre...</td>\n",
       "      <td>super delay tbw list #academicbreaknow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29588</th>\n",
       "      <td>si taylor nay nag implement ug academic break</td>\n",
       "      <td>si taylor nay nag implement ug academic break</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29589</th>\n",
       "      <td>Actually Lenin wasn t peer reviewed by establi...</td>\n",
       "      <td>actually lenin peer reviewed established acade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>Academic break plss</td>\n",
       "      <td>academic break plss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29591</th>\n",
       "      <td>tangina hirap magpa chill chill hahaha daming ...</td>\n",
       "      <td>tangina hirap magpa chill chill hahaha daming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29592</th>\n",
       "      <td>Nakakatuwa ang tamad ko pero gusto ko ng acade...</td>\n",
       "      <td>nakakatuwa tamad academic freeze ganito putangina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29593 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    absolute_tidy_tweets  \\\n",
       "0                                      #academicbreaknow   \n",
       "1      Hello #AcademicTwitter You need to have a rest...   \n",
       "2                  lunes nanaman bukas #academicbreaknow   \n",
       "3         #AcademicBreakNow gusto q na tapusin Wednesday   \n",
       "4      super delay na ako sa tbw list ko #academicbre...   \n",
       "...                                                  ...   \n",
       "29588      si taylor nay nag implement ug academic break   \n",
       "29589  Actually Lenin wasn t peer reviewed by establi...   \n",
       "29590                                Academic break plss   \n",
       "29591  tangina hirap magpa chill chill hahaha daming ...   \n",
       "29592  Nakakatuwa ang tamad ko pero gusto ko ng acade...   \n",
       "\n",
       "                                          stopped_tweets  \n",
       "0                                      #academicbreaknow  \n",
       "1      hello #academictwitter need rest activate best...  \n",
       "2                  lunes nanaman bukas #academicbreaknow  \n",
       "3                  #academicbreaknow q tapusin wednesday  \n",
       "4                 super delay tbw list #academicbreaknow  \n",
       "...                                                  ...  \n",
       "29588      si taylor nay nag implement ug academic break  \n",
       "29589  actually lenin peer reviewed established acade...  \n",
       "29590                                academic break plss  \n",
       "29591  tangina hirap magpa chill chill hahaha daming ...  \n",
       "29592  nakakatuwa tamad academic freeze ganito putangina  \n",
       "\n",
       "[29593 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "conceptual-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_char(text):\n",
    "    clean_tweet = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    clean_tweet = re.sub(\"#[A-Za-z0-9_]+\",\"\", clean_tweet)\n",
    "    return clean_tweet\n",
    "dataset['absolute_tidy_tweets']=dataset['absolute_tidy_tweets'].apply(clean_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "running-cleveland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_tidy_tweets</th>\n",
       "      <th>stopped_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>#academicbreaknow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello  You need to have a rest To activate you...</td>\n",
       "      <td>hello #academictwitter need rest activate best...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lunes nanaman bukas</td>\n",
       "      <td>lunes nanaman bukas #academicbreaknow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gusto q na tapusin Wednesday</td>\n",
       "      <td>#academicbreaknow q tapusin wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>super delay na ako sa tbw list ko</td>\n",
       "      <td>super delay tbw list #academicbreaknow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29588</th>\n",
       "      <td>si taylor nay nag implement ug academic break</td>\n",
       "      <td>si taylor nay nag implement ug academic break</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29589</th>\n",
       "      <td>Actually Lenin wasn t peer reviewed by establi...</td>\n",
       "      <td>actually lenin peer reviewed established acade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>Academic break plss</td>\n",
       "      <td>academic break plss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29591</th>\n",
       "      <td>tangina hirap magpa chill chill hahaha daming ...</td>\n",
       "      <td>tangina hirap magpa chill chill hahaha daming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29592</th>\n",
       "      <td>Nakakatuwa ang tamad ko pero gusto ko ng acade...</td>\n",
       "      <td>nakakatuwa tamad academic freeze ganito putangina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29593 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    absolute_tidy_tweets  \\\n",
       "0                                                          \n",
       "1      Hello  You need to have a rest To activate you...   \n",
       "2                                   lunes nanaman bukas    \n",
       "3                           gusto q na tapusin Wednesday   \n",
       "4                     super delay na ako sa tbw list ko    \n",
       "...                                                  ...   \n",
       "29588      si taylor nay nag implement ug academic break   \n",
       "29589  Actually Lenin wasn t peer reviewed by establi...   \n",
       "29590                                Academic break plss   \n",
       "29591  tangina hirap magpa chill chill hahaha daming ...   \n",
       "29592  Nakakatuwa ang tamad ko pero gusto ko ng acade...   \n",
       "\n",
       "                                          stopped_tweets  \n",
       "0                                      #academicbreaknow  \n",
       "1      hello #academictwitter need rest activate best...  \n",
       "2                  lunes nanaman bukas #academicbreaknow  \n",
       "3                  #academicbreaknow q tapusin wednesday  \n",
       "4                 super delay tbw list #academicbreaknow  \n",
       "...                                                  ...  \n",
       "29588      si taylor nay nag implement ug academic break  \n",
       "29589  actually lenin peer reviewed established acade...  \n",
       "29590                                academic break plss  \n",
       "29591  tangina hirap magpa chill chill hahaha daming ...  \n",
       "29592  nakakatuwa tamad academic freeze ganito putangina  \n",
       "\n",
       "[29593 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "disciplinary-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_positive(text):\n",
    "    tk = WhitespaceTokenizer()\n",
    "    tokens = tk.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    positive = 0\n",
    "    for token in tokens:\n",
    "        if token in positive_data:\n",
    "            positive = positive + 1\n",
    "    return positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "convinced-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_negative(text):\n",
    "    tk = WhitespaceTokenizer()\n",
    "    tokens = tk.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    negative = 0\n",
    "    for token in tokens:\n",
    "        if token in negative_data:\n",
    "            negative = negative -1\n",
    "    return negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "complicated-tanzania",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-91bb812e06a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'positive'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stopped_tweets'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_positive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-eae1b3802050>\u001b[0m in \u001b[0;36mlabel_positive\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlabel_positive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWhitespaceTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpositive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\regexp.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gaps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_discard_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtok\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_regexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtok\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_regexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "dataset['positive']=dataset['stopped_tweets'].apply(label_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['negative']=dataset['stopped_tweets'].apply(label_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_token(text):\n",
    "    tk = WhitespaceTokenizer()\n",
    "    tokens = tk.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    count = len(tokens)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['total']=dataset['stopped_tweets'].apply(count_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-choice",
   "metadata": {},
   "source": [
    "# Compute for Sentiment Score\n",
    "* 1 to 0.5 — generally positive sentiment\n",
    "* 0.5 to -0.5 — neutral sentiment\n",
    "* -0.5 to -1 — negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['StSc'] = (dataset.positive - dataset.negative)/dataset.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('Sentiment_score.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-ferry",
   "metadata": {},
   "source": [
    "# Label Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentiment(score):\n",
    "    sentiment = 0\n",
    "    if score >= 0.05:\n",
    "        sentiment = 1\n",
    "    elif score < 0.05 and score > -0.05:\n",
    "        sentiment = 0\n",
    "    else:\n",
    "        senitment = -1\n",
    "    return sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['sentiment']=dataset['StSc'].apply(label_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('Sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-binding",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
